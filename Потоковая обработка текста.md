
### find

Незаменим для очистки логов, поиска конфигов и автоматизации.

- `-name "*.log"` — поиск по имени (чувствителен к регистру).
- `-iname` — поиск по имени (регистр НЕ важен).
- `-type f` — только файлы; `-type d` — только директории.
- `-mtime -7` — файлы, измененные за последние 7 дней.
- `-size +100M` — файлы тяжелее 100 Мегабайт.
- `-exec ... {} \;` — выполнить команду над каждым найденным файлом.

Пример: `find /var/log -name "*.log" -mtime +30 -exec rm {} \;` (удалить логи старше 30 дней).

### awk (Программируемый фильтр)

Самый мощный инструмент для работы с табличными данными и логами.

- **Синтаксис:** `awk -F'разделитель' 'условие { действие }' файл`
- **Ключевые переменные:**
    - `$0` — вся строка целиком.
    - `$1`, `$2`, `$3`... — номера полей (столбцов).
    - `$NF` — (**Number** of **Fields**) значение _последнего_ поля в строке.
    - `NR` — (**Number** of **Record**) номер текущей строки.
        
- **Полезные флаги и операторы:**
    - `-F` — задать разделитель (по умолчанию пробел/tab). Пример: `-F':'`.
    - `print` — вывести на экран.
    - `length($0) > 10` — фильтр по длине строки.
        
- **Пример:**

```bash
    # Вывести 1-е и последнее поле, если 3-е больше 1000
    awk -F: '$3 > 1000 {print $1, $NF}' /etc/passwd
```

### cut

Быстрый способ вырезать колонки, если структура файла простая и жесткая.

- **Синтаксис:** `cut [опции] файл`
- **Ключевые флаги:**
    - `-d 'delimiter'` — установить разделитель (только один символ!).
    - `-f N` — выбрать поле(столбец, колонку) номер N.
    - `-f N-M` — выбрать диапазон полей (с N по M).
    - `-c N-M` — вырезать по символам (не по полям).

- **Пример:**

```bash
    # Взять 1-ю и 7-ю колонку из CSV
    cut -d ',' -f 1,7 data.csv
```

### sort 

Упорядочивает строки. Критически важен перед использованием `uniq`.

- **Синтаксис:** `sort [опции] файл`
- **Ключевые флаги:**
    - `-n` (**Numeric**) — числовая сортировка (иначе "10" будет раньше "2").
    - `-r` (**Reverse**) — сортировка в обратном порядке (от большего к меньшему).
    - `-k N` (**Key**) — сортировать по конкретному столбцу N.
    - `-u` (**Unique**) — сразу удалить дубликаты (аналог `sort | uniq`).
    
- **Пример:**

```bash
sort -k 3 -nr table.txt   # Сортировать по 3-й колонке как числа, по убыванию
```

### uniq 

Фильтрует или подсчитывает _повторяющиеся подряд_ строки.

- **Синтаксис:** `uniq [опции]`
- **Важно:** Работает только на отсортированном вводе! Всегда делай `sort | uniq`.
- **Ключевые флаги:**
    - `-c` (**Count**) — вывести количество повторений (самый частый кейс).
    - `-d` (**Duplicate**) — показать только то, что повторяется.
    - `-u` (**Unique**) — показать только то, что встречается 1 раз.
    
- **Пример:**

```bash
sort access.log | uniq -c    # Посчитать, сколько раз встречается каждый IP
```

### tr

Работает только с потоком (stdin), не умеет читать файлы напрямую. Идеален для чистки мусора.

- **Синтаксис:** `cat файл | tr [опции] 'set1' 'set2'`
- **Ключевые флаги:**
    
    - `-d` (**Delete**) — удалить символы, указанные в наборе.
    - `-s` (**Squeeze**) — сжать повторяющиеся символы в один (например, лишние пробелы).
- **Пример:**

```bash
    # Удалить все цифры из вывода
    echo "H3ll0 W0rld" | tr -d '0-9'  # Вывод: Hll Wrld
    # Сменить регистр на верхний
    echo "hello" | tr 'a-z' 'A-Z'
```

###  wc (word count)

Счетчик.

- **Синтаксис:** `wc [опции]`
- **Ключевые флаги:**
    - `-l` (**Lines**) — количество строк (используется в 99% случаев).
    - `-w` (**Words**) — количество слов.
    - `-c` (**Bytes**) — количество байт.

---

### **Best Practices & Patterns (Шаблоны)**

1. **"Топ-N" (Аналитика логов):** Стандартная связка для выяснения "Кто больше всех грузит сервер?" или "Какая ошибка самая частая?":

```bash
... | sort | uniq -c | sort -nr | head -n 10
```

1. **Очистка "грязного" вывода:** Если в логах много лишних пробелов, `cut` может сломаться. Используй `tr -s ' '` или сразу `awk`, так как `awk` игнорирует множественные пробелы по умолчанию.
    
    - _Плохо:_ `cut -d ' ' ...` (сломается на двойном пробеле).
    - _Хорошо:_ `awk '{print $2}'` (сработает всегда).
        
2. **Поиск в реальном времени:** Используй `watch`, чтобы перезапускать пайплайн каждые 2 секунды.

```bash
watch -n 1 "ps aux | grep node | wc -l"
```

### **Pro-Tips (из реальной жизни)**

1. **Комбинация find + xargs:** Если `find -exec` создает новый процесс на каждый файл (медленно), то `xargs` группирует их, что работает в разы быстрее.
2. **Скорость grep:** Если нужно просто найти строку в огромном файле, `LC_ALL=C grep` будет работать быстрее, так как не тратит ресурсы на поддержку различных кодировок (UTF-8).
3. **Проверка awk:** Прежде чем запускать сложный `awk` скрипт, всегда проверяй его на одной строке через `head -n 1 | awk ...`.

### **Подводные камни**

- **Пробелы в именах файлов:** `find` и `xargs` могут "сломаться" на именах с пробелами. Используй связку `find -print0 | xargs -0` — это заменяет разделитель на нулевой символ, который уникален.
- **Сортировка чисел без -n:** Запомни: без флага `-n` строка "100" будет стоять выше, чем "2", потому что "1" меньше "2".